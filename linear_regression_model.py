# -*- coding: utf-8 -*-
"""Linear Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10VqpFgg8HvZa3qz6QY4JmdlH-7HmEVoG

# **1. Import Libraries**
This section imports all necessary packages for data handling (pandas, numpy), visualization (seaborn, matplotlib), and machine learning (scikit-learn).
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error

"""# **2. Load and Inspect Data**
Load the dataset and perform initial exploration to understand its structure and find missing and duplicate values.
"""

# Load the dataset
data = pd.read_csv('/content/insurance_data.csv')

data

# Display basic information
print("------- Data set Information ------")
data.info()

# Check for missing values
print("\n--------- Missing Values ---------")
print(data.isnull().sum())

# Check for duplicate values
print(f'Number of duplicate values = {data.duplicated().sum()}')

"""# **3. Data Preprocessing & Cleaning**
This is a critical phase. We fill missing values, remove extreme outliers that could skew the model, and convert categorical text data into numbers the model can understand.
"""

# --- 3.1 Impute Missing Values ---
# Fill missing numerical values with the median
# Fill missing categorical values with the mode
for i in data.columns:
    if data[i].dtypes == 'object':
        data[i] = data[i].fillna(data[i].mode()[0])
    else:
        data[i] = data[i].fillna(data[i].median())

# --- 3.2 check for outlier values---
for col in data.columns:
  if data[col].dtypes != 'object':
    sns.boxplot(data[col])
    plt.title(col)
    plt.show()

# --- Handle Outliers using IQR ---
# Removing extreme outliers to create a more stable and accurate model
outlier_list = ['bmi', 'past_consultations', 'Hospital_expenditure', 'Anual_Salary']

for col in outlier_list:
    Q1 = data[col].quantile(0.25)
    Q3 = data[col].quantile(0.75)
    IQR = Q3 - Q1
    lb = Q1 - 1.5 * IQR
    ub = Q3 + 1.5 * IQR

    # Filter the data to keep only rows within the non-outlier range
    data = data[(data[col] >= lb) & (data[col] <= ub)]

# --- 3.3. Encode Categorical Features ---
# Convert object columns (like 'sex', 'smoker', 'region') into numerical values
le = LabelEncoder()
for i in data.columns:
    if data[i].dtypes == 'object':
        data[i] = le.fit_transform(data[i])

print(f"Data Shape After Cleaning: {data.shape}")

"""# **4. Feature Scaling & Model Preparation**
We separate our features (X) from our target (Y). Then, we scale the features so that all columns have a similar range, which is crucial for Linear Regression.
"""

# --- 4.1. Define Features (X) and Target (Y)---
X = data.drop('charges', axis=1)
Y = data['charges']

# --- 4.2. Split Data into Training and Testing Sets ---
x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=23, test_size=0.25)

# --- 4.3. Scale Features ---
# Scaling is vital for linear models to ensure all features are weighted appropriately
scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_test_scaled = scaler.transform(x_test)

"""# **5. Model Training and Evaluation**
Now we train the Linear Regression model on our prepared data and evaluate its performance on the unseen test data.
"""

# --- 5.1. Train the Linear Regression Model ---
linear_model = LinearRegression()
linear_model.fit(x_train_scaled, y_train)

# --- 5.2. Make Predictions ---
y_pred = linear_model.predict(x_test_scaled)

# --- 5.3. Evaluate Model Performance ---
acc = r2_score(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)

print("\n--- Model Performance ---")
print(f'R-squared (Accuracy) of the model is {acc*100:.2f}%.')
print(f'Mean Squared Error (MSE) is {mse:.2f}.')
print(f'Root Mean Squared Error (RMSE) is {rmse:.2f}.')

"""# **6. Model Interpretation**
We can inspect the model's coefficients to see which features had the biggest impact on predicting the final insurance charges.
"""

# --- 6.1. Analyze Feature Importance ---
coefficients = pd.DataFrame(linear_model.coef_, X.columns, columns=['Coefficient'])
print("\n--- Feature Importance (Coefficients) ---")
print(coefficients.sort_values(by='Coefficient', ascending=False))